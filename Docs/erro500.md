# Erro 500 no Endpoint `/api/chat/` - Requer Ajuda

> **Status:** ‚ö†Ô∏è **PENDENTE** - Tentativas de solu√ß√£o implementadas mas erro persiste  
> **Data:** 29 de Novembro de 2025  
> **Ambiente:** Desenvolvimento Local  
> **Prioridade:** üî¥ Alta

---

## üìã Resumo Executivo

### Problema Principal
O endpoint `/api/chat/` est√° retornando **erro 500 (Internal Server Error** quando tenta gerar respostas usando o LangChain com ChatGroq.

### Erro Espec√≠fico
```
TypeError: Completions.create() got an unexpected keyword argument 'reasoning_format'
```

### Impacto
- Endpoint de chat completamente inoperante
- Usu√°rios n√£o conseguem usar o Chef Virtual
- Erro ocorre em todas as requisi√ß√µes ao endpoint

---

## üêõ Erro Detalhado

### Mensagem de Erro Completa
```
TypeError: Completions.create() got an unexpected keyword argument 'reasoning_format'
```

### Traceback Completo (dos logs do backend)
```
Traceback (most recent call last):
  File "/home/brunoadsba/ifood/tastematch/backend/app/api/routes/chat.py", line 202, in chat
    response = get_chef_response(
               ^^^^^^^^^^^^^^^^^^
  File "/home/brunoadsba/ifood/tastematch/backend/app/core/chef_chat.py", line 1000, in get_chef_response
    answer = chain.invoke(question, config={"callbacks": [monitoring_callback]})
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/brunoadsba/ifood/tastematch/venv/lib/python3.11/site-packages/langchain_core/runnables/base.py", line 3046, in invoke
    input_ = context.run(step.invoke, input_, config)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/brunoadsba/ifood/tastematch/venv/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py", line 395, in invoke
    self.generate_prompt(
  File "/home/brunoadsba/ifood/tastematch/venv/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py", line 980, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/brunoadsba/ifood/tastematch/venv/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py", line 799, in generate
    self._generate_with_cache(
  File "/home/brunoadsba/ifood/tastematch/venv/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py", line 1045, in _generate_with_cache
    result = self._generate(
             ^^^^^^^^
  File "/home/brunoadsba/ifood/tastematch/venv/lib/python3.11/site-packages/langchain_groq/chat_models.py", line 504, in _generate
    response = self.client.create(messages=message_dicts, **params)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Completions.create() got an unexpected keyword argument 'reasoning_format'
```

### Quando Ocorre
- Toda vez que o endpoint `/api/chat/` recebe uma requisi√ß√£o v√°lida
- Ap√≥s autentica√ß√£o bem-sucedida
- Ap√≥s valida√ß√£o da pergunta
- Durante a execu√ß√£o do chain LangChain para gerar resposta

---

## üîß Contexto do Ambiente

### Vers√µes de Depend√™ncias Cr√≠ticas
```txt
langchain==0.3.27
langchain-core==0.3.72
langchain-groq==0.3.3
groq==0.4.1
pydantic==2.7.4
pydantic-settings==2.12.0
```

### Configura√ß√µes Relevantes
- **Modelo LLM:** `llama-3.1-8b-instant`
- **Ambiente:** Desenvolvimento local
- **Python:** 3.11
- **Backend:** FastAPI 0.104.1
- **GROQ_API_KEY:** Configurada e validada

### Ambiente
- **Local:** `http://localhost:8000`
- **Database:** PostgreSQL local (Docker) na porta 5432
- **Extens√£o pgvector:** Instalada e funcionando

---

## ‚úÖ Tentativas de Solu√ß√£o J√° Implementadas

### 1. Wrapper `ChatGroqFiltered` (Status: ‚ö†Ô∏è N√ÉO RESOLVIDO)

**Localiza√ß√£o:** `backend/app/core/chef_chat.py` (linhas 26-45)

**Implementa√ß√£o:**
```python
class ChatGroqFiltered(ChatGroq):
    """
    Wrapper do ChatGroq que filtra par√¢metros n√£o suportados como 'reasoning_format'.
    """
    
    def _generate(
        self,
        messages: List[BaseMessage],
        stop: Optional[List[str]] = None,
        run_manager: Optional[Any] = None,
        **kwargs: Any,
    ) -> Any:
        """Override para filtrar par√¢metros n√£o suportados."""
        # Remover par√¢metros de reasoning que n√£o s√£o suportados
        filtered_kwargs = {k: v for k, v in kwargs.items() 
                          if k not in ['reasoning_format', 'reasoning_effort']}
        return super()._generate(messages, stop=stop, run_manager=run_manager, **filtered_kwargs)
```

**Uso:**
```python
llm = ChatGroqFiltered(
    groq_api_key=settings.GROQ_API_KEY,
    model="llama-3.1-8b-instant",
    temperature=0.5
)
```

**Problema:** O wrapper foi criado mas o erro persiste. O par√¢metro `reasoning_format` pode estar sendo adicionado em outro lugar do fluxo, ou o override n√£o est√° interceptando corretamente.

### 2. Handler Global de Exce√ß√µes (Status: ‚úÖ IMPLEMENTADO)

**Localiza√ß√£o:** `backend/app/main.py` (linhas 72-104)

**Fun√ß√£o:** Captura todas as exce√ß√µes n√£o tratadas e loga com traceback completo.

### 3. Logging Melhorado (Status: ‚úÖ IMPLEMENTADO)

**Localiza√ß√£o:** `backend/app/api/routes/chat.py`

**Fun√ß√£o:** Logging detalhado com traceback completo para facilitar debug.

---

## üìù Informa√ß√µes T√©cnicas

### Arquivos Envolvidos
1. `backend/app/api/routes/chat.py` - Endpoint que recebe a requisi√ß√£o
2. `backend/app/core/chef_chat.py` - L√≥gica do Chef Virtual e cria√ß√£o do LLM
3. `backend/app/core/llm_monitoring.py` - Callback de monitoramento
4. `venv/lib/python3.11/site-packages/langchain_groq/chat_models.py:504` - Onde o erro ocorre

### Stack Trace Completo
O erro ocorre na seguinte sequ√™ncia:
1. `chat()` endpoint recebe requisi√ß√£o POST
2. Valida pergunta e obt√©m RAG service
3. Chama `get_chef_response()` 
4. Cria chain LangChain com `create_chef_chain()`
5. Executa `chain.invoke()` com callback
6. LangChain chama `ChatGroq._generate()`
7. `langchain_groq` tenta passar `reasoning_format` para API Groq
8. **ERRO:** API Groq rejeita par√¢metro n√£o suportado

### Onde o Par√¢metro Est√° Sendo Adicionado

O par√¢metro `reasoning_format` est√° sendo adicionado em algum lugar do fluxo LangChain, possivelmente:
- No `langchain_groq` baseado em alguma configura√ß√£o do modelo
- No `langchain-core` como par√¢metro padr√£o
- Em alguma configura√ß√£o do chain que n√£o estamos vendo

---

## ‚ùì Perguntas para o Dev/IA que Vai Ajudar

1. **O par√¢metro `reasoning_format` est√° sendo adicionado onde?**
   - Est√° vindo do `langchain-groq` internamente?
   - Est√° sendo adicionado pelo `langchain-core`?
   - Como identificar a origem exata?

2. **O wrapper `ChatGroqFiltered` n√£o est√° funcionando. Por qu√™?**
   - O override do `_generate()` est√° correto?
   - O par√¢metro est√° sendo adicionado depois do `_generate()`?
   - Existe outro m√©todo que preciso sobrescrever?

3. **Como interceptar o par√¢metro antes que chegue na API Groq?**
   - Existe um m√©todo melhor que `_generate()`?
   - Preciso criar um wrapper no cliente Groq tamb√©m?
   - H√° configura√ß√£o que desabilita esses par√¢metros?

4. **Existe alternativa melhor?**
   - Atualizar vers√£o do `langchain-groq`?
   - Mudar de modelo LLM?
   - Usar outra biblioteca de integra√ß√£o com Groq?

5. **O erro pode estar relacionado a vers√µes das depend√™ncias?**
   - As vers√µes atuais s√£o compat√≠veis?
   - Existe incompatibilidade conhecida?

---

## üîç An√°lise do C√≥digo

### Cria√ß√£o do ChatGroq

**Localiza√ß√£o:** `backend/app/core/chef_chat.py:339-343`

```python
llm = ChatGroqFiltered(
    groq_api_key=settings.GROQ_API_KEY,
    model="llama-3.1-8b-instant",
    temperature=0.5
)
```

### Execu√ß√£o do Chain

**Localiza√ß√£o:** `backend/app/core/chef_chat.py:1000`

```python
answer = chain.invoke(question, config={"callbacks": [monitoring_callback]})
```

### Chain Criado

**Localiza√ß√£o:** `backend/app/core/chef_chat.py:338-600+`

A chain √© criada usando LCEL (LangChain Expression Language) e envolve:
- RAG retrieval
- Prompt template
- LLM (ChatGroqFiltered)
- Output parser

---

## üß™ Como Reproduzir o Erro

### Pr√©-requisitos
1. PostgreSQL local rodando na porta 5432
2. Backend iniciado com `DATABASE_URL` local
3. `GROQ_API_KEY` configurada no `.env`
4. Usu√°rio autenticado

### Passos
1. Iniciar backend:
```bash
cd /home/brunoadsba/ifood/tastematch/backend
export DATABASE_URL="postgresql://tastematch:tastematch_dev@localhost:5432/tastematch"
python -m uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload
```

2. Fazer requisi√ß√£o POST para `/api/chat/`:
```bash
curl -X POST http://localhost:8000/api/chat/ \
  -H "Content-Type: multipart/form-data" \
  -H "Authorization: Bearer <TOKEN>" \
  -F "message=quero um restaurante italiano"
```

3. Verificar logs do backend - erro aparecer√° ap√≥s ~3-5 segundos

### Logs Esperados
```
ERROR app.core.llm_monitoring - Erro no LLM: Completions.create() got an unexpected keyword argument 'reasoning_format'
ERROR app.api.routes.chat - Erro ao gerar resposta do Chef: Completions.create() got an unexpected keyword argument 'reasoning_format'
[Traceback completo...]
ERROR app.main - POST /api/chat/ - 500 [endpoint=/api/chat/, duration=4181.02ms]
```

---

## üìö Refer√™ncias e Contexto Adicional

### Documenta√ß√£o Relacionada
- `Docs/DEBUG_ERRO_500_CHAT.md` - Primeira investiga√ß√£o
- `Docs/ANALISE_ERRO_500_CHAT.md` - An√°lise baseada em li√ß√µes aprendidas
- `Docs/SOLUCAO_ERRO_500_CHAT_REASONING_FORMAT.md` - Tentativa de solu√ß√£o

### Li√ß√µes Aprendidas Relevantes
- Conflitos de depend√™ncias foram resolvidos anteriormente
- Configura√ß√£o expl√≠cita √© melhor que detec√ß√£o autom√°tica
- Logging estruturado facilita debug

---

## üéØ Pr√≥ximos Passos Sugeridos

1. Investigar onde `reasoning_format` est√° sendo adicionado no fluxo LangChain
2. Verificar se h√° configura√ß√£o no `langchain-groq` que adiciona esse par√¢metro
3. Tentar interceptar em outro n√≠vel (cliente Groq, configura√ß√£o do chain, etc.)
4. Considerar atualiza√ß√£o ou downgrade de vers√µes se necess√°rio
5. Verificar se h√° issues conhecidos no reposit√≥rio `langchain-groq`

---

## üìû Informa√ß√µes de Contato / Contexto

- **Projeto:** TasteMatch - Agente de Recomenda√ß√£o Inteligente
- **Ambiente Atual:** Desenvolvimento Local
- **Deploy em Produ√ß√£o:** Funciona (usa Supabase, pode ter comportamento diferente)
- **√öltima Modifica√ß√£o:** 29/11/2025 17:13
- **Status:** üî¥ **REQUER AJUDA URGENTE**

---

**Nota:** Este documento foi criado para facilitar a colabora√ß√£o com outros desenvolvedores ou IAs. Todas as informa√ß√µes relevantes est√£o inclu√≠das para diagn√≥stico r√°pido.

