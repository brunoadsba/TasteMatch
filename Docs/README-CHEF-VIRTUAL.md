# Chef Virtual - DocumentaÃ§Ã£o Completa

**VersÃ£o**: 1.0.3  
**Data**: 30/11/2025  
**Status**: âœ… 100% Completo - Rodando Localmente

---

## ğŸ“‹ Ãndice

1. [VisÃ£o Geral](#visÃ£o-geral)
2. [Arquitetura](#arquitetura)
3. [InstalaÃ§Ã£o e ConfiguraÃ§Ã£o](#instalaÃ§Ã£o-e-configuraÃ§Ã£o)
4. [Uso](#uso)
5. [Monitoramento](#monitoramento)
6. [Troubleshooting](#troubleshooting)
7. [LiÃ§Ãµes Aprendidas](#liÃ§Ãµes-aprendidas)
8. [ReferÃªncias](#referÃªncias)

---

## ğŸ¯ VisÃ£o Geral

O **Chef Virtual** Ã© um chatbot conversacional integrado ao TasteMatch que ajuda usuÃ¡rios a encontrar restaurantes e pratos usando inteligÃªncia artificial. O sistema utiliza:

- **RAG (Retrieval-Augmented Generation)** com PGVector para busca semÃ¢ntica
- **Hybrid Search** combinando busca exata e semÃ¢ntica
- **LLM Groq** (Llama-3.1-8b-instant) para geraÃ§Ã£o de respostas
- **STT/TTS** para suporte a Ã¡udio (Groq Whisper + Edge-TTS)
- **Monitoramento completo** de mÃ©tricas LLM

### Funcionalidades Principais

- âœ… Chat conversacional sobre restaurantes e comida
- âœ… RecomendaÃ§Ãµes personalizadas baseadas em preferÃªncias
- âœ… Suporte a texto e Ã¡udio (gravaÃ§Ã£o e reproduÃ§Ã£o)
- âœ… HistÃ³rico de conversas persistido
- âœ… PrevenÃ§Ã£o de alucinaÃ§Ã£o e validaÃ§Ã£o de respostas
- âœ… InteraÃ§Ãµes sociais naturais (saudaÃ§Ãµes, agradecimentos)
- âœ… Filtro semÃ¢ntico rigoroso para recomendaÃ§Ãµes precisas
- âœ… Tratamento inteligente de queries especÃ­ficas (sopa, aÃ§aÃ­, churrasco, etc.)
- âœ… Respostas limpas sem seÃ§Ãµes desnecessÃ¡rias
- âœ… Monitoramento de latÃªncia, tokens e custo
- âœ… Rate limiting (30 requisiÃ§Ãµes/minuto)

---

## ğŸ—ï¸ Arquitetura

### Componentes Principais

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend      â”‚
â”‚   (React)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   FastAPI       â”‚
â”‚   Backend       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
    â–¼         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  RAG   â”‚ â”‚   LLM   â”‚
â”‚Service â”‚ â”‚  Groq   â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
     â”‚          â”‚
     â–¼          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PGVector â”‚ â”‚Monitoringâ”‚
â”‚(Postgres)â”‚ â”‚  (DB)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Fluxo de Dados

1. **UsuÃ¡rio envia mensagem** (texto ou Ã¡udio)
2. **Backend processa**:
   - Se Ã¡udio: STT (Groq Whisper) â†’ texto
   - RAG busca contexto relevante (PGVector + Hybrid Search)
   - LLM gera resposta (Groq Llama)
   - Monitoramento coleta mÃ©tricas
3. **Resposta retornada**:
   - Texto formatado
   - Opcionalmente: Ã¡udio (TTS via Edge-TTS)

### Tecnologias

- **Backend**: FastAPI, Python 3.10+
- **Frontend**: React, TypeScript
- **Banco de Dados**: PostgreSQL com PGVector
- **LLM**: Groq (Llama-3.1-8b-instant)
- **Embeddings**: HuggingFace (paraphrase-multilingual-MiniLM-L12-v2)
- **STT**: Groq Whisper API
- **TTS**: Edge-TTS
- **Rate Limiting**: slowapi

---

## ğŸš€ InstalaÃ§Ã£o e ConfiguraÃ§Ã£o

### PrÃ©-requisitos

- Python 3.10+
- PostgreSQL 16+ com extensÃ£o pgvector
- Node.js 18+ (para frontend)
- Docker (opcional, para PostgreSQL)

### Backend

1. **Instalar dependÃªncias**:
```bash
cd tastematch/backend
pip install -r requirements.txt
```

2. **Configurar variÃ¡veis de ambiente** (`.env`):
```env
DATABASE_URL=postgresql://tastematch:tastematch_dev@localhost:5432/tastematch
GROQ_API_KEY=sua_chave_groq_aqui
SECRET_KEY=sua_chave_secreta_aqui
```

3. **Executar migrations**:
```bash
alembic upgrade head
```

4. **Inicializar base de conhecimento**:
```bash
python -c "from app.core.knowledge_base import update_knowledge_base; from app.database.base import get_db; update_knowledge_base(next(get_db()))"
```

5. **Iniciar servidor**:
```bash
uvicorn app.main:app --reload
```

### Frontend

1. **Instalar dependÃªncias**:
```bash
cd tastematch/frontend
npm install
```

2. **Configurar variÃ¡veis** (`.env`):
```env
VITE_API_URL=http://localhost:8000
```

3. **Iniciar servidor de desenvolvimento**:
```bash
npm run dev
```

### Docker (PostgreSQL)

```bash
cd tastematch
docker-compose up -d postgres
```

---

## ğŸ’» Uso

### API Endpoints

#### `POST /api/chat/`
Envia mensagem ao Chef Virtual.

**Request**:
```json
{
  "message": "Quero uma pizza"
}
```

**Response**:
```json
{
  "answer": "Recomendo a Pizzaria Bella...",
  "audio_url": "http://localhost:8000/api/chat/audio/response_123.mp3",
  "source_documents": [...],
  "validation": {
    "confidence_score": 0.95,
    "total_sources": 5,
    "restaurant_sources": 3
  }
}
```

#### `GET /api/chat/history`
ObtÃ©m histÃ³rico de conversas.

#### `GET /api/llm/summary`
ObtÃ©m resumo de mÃ©tricas LLM.

**Query Parameters**:
- `days` (opcional): NÃºmero de dias (1-90, padrÃ£o: 7)
- `user_id` (opcional): ID do usuÃ¡rio

**Response**:
```json
{
  "user_id": 1,
  "days": 7,
  "summary": {
    "total_calls": 150,
    "total_tokens": 318000,
    "total_cost_usd": 0.0159,
    "avg_latency_ms": 650,
    "error_rate": 0.0
  },
  "timestamp": "2025-01-XXT..."
}
```

### Frontend

O Chef Virtual estÃ¡ disponÃ­vel no Dashboard atravÃ©s de um botÃ£o flutuante (FAB) no canto inferior direito.

**Funcionalidades**:
- Chat em tempo real
- GravaÃ§Ã£o de Ã¡udio
- ReproduÃ§Ã£o de respostas em Ã¡udio
- HistÃ³rico de conversas
- Estados visuais (listening, thinking, speaking)

---

## ğŸ“Š Monitoramento

### MÃ©tricas Coletadas

O sistema coleta automaticamente:

- **LatÃªncia**: Tempo de resposta do LLM (ms)
- **Tokens**: Input, output e total
- **Custo**: Estimado em USD (baseado em preÃ§os Groq)
- **Tamanho da resposta**: Caracteres
- **Erros**: Mensagens de erro (se houver)

### VisualizaÃ§Ã£o

1. **Endpoint de mÃ©tricas**: `GET /api/llm/summary`
2. **Banco de dados**: Tabela `llm_metrics`
3. **Logs estruturados**: Console/arquivo de log

### Exemplo de Consulta SQL

```sql
-- Ãšltimas 10 chamadas
SELECT 
    model,
    total_tokens,
    latency_ms,
    estimated_cost_usd,
    created_at
FROM llm_metrics
ORDER BY created_at DESC
LIMIT 10;

-- Resumo diÃ¡rio
SELECT 
    DATE(created_at) as date,
    COUNT(*) as calls,
    SUM(total_tokens) as tokens,
    SUM(estimated_cost_usd) as cost,
    AVG(latency_ms) as avg_latency
FROM llm_metrics
GROUP BY DATE(created_at)
ORDER BY date DESC;
```

---

## ğŸ”§ Troubleshooting

### Problemas Comuns

#### 1. Erro de conexÃ£o com banco
```
OperationalError: connection to server at "localhost" failed
```
**SoluÃ§Ã£o**: Verificar se PostgreSQL estÃ¡ rodando:
```bash
docker ps | grep postgres
# ou
systemctl status postgresql
```

#### 2. Erro "GROQ_API_KEY nÃ£o configurada"
**SoluÃ§Ã£o**: Adicionar `GROQ_API_KEY` no arquivo `.env`

#### 3. Rate limit excedido (429)
**SoluÃ§Ã£o**: Aguardar 1 minuto ou aumentar limite no cÃ³digo (nÃ£o recomendado)

#### 4. Embeddings nÃ£o encontrados
**SoluÃ§Ã£o**: Inicializar base de conhecimento:
```bash
python -c "from app.core.knowledge_base import update_knowledge_base; from app.database.base import get_db; update_knowledge_base(next(get_db()))"
```

#### 5. Erro ao processar Ã¡udio
**SoluÃ§Ã£o**: Verificar se FFmpeg estÃ¡ instalado:
```bash
ffmpeg -version
```

### Logs

Logs estruturados sÃ£o gerados automaticamente. Em produÃ§Ã£o, configure para arquivo:

```python
# app/core/logging_config.py
file_handler = logging.FileHandler('app.log')
```

---

## ğŸ“š LiÃ§Ãµes Aprendidas

### 1. Escolha de Tecnologias

**PGVector vs FAISS**:
- âœ… PGVector: PersistÃªncia garantida, backup automÃ¡tico, integrado ao banco
- âŒ FAISS: Requer volume persistente, mais complexo de gerenciar
- **DecisÃ£o**: PGVector foi a melhor escolha para produÃ§Ã£o

**Hybrid Search**:
- âœ… Combina busca exata (SQL) + semÃ¢ntica (embeddings)
- âœ… Melhor precisÃ£o para nomes de restaurantes
- âœ… Prioriza resultados exatos sobre semÃ¢nticos

### 2. Prompt Engineering

**Desafios**:
- LLM tendia a ser verboso e repetitivo
- Frases desnecessÃ¡rias ("Com base no contexto", "Eu diria que")
- RepetiÃ§Ã£o de perguntas do usuÃ¡rio

**SoluÃ§Ãµes**:
- Regras explÃ­citas no prompt
- Post-processamento com `clean_answer()`
- DetecÃ§Ã£o de interaÃ§Ãµes sociais (bypass do LLM)
- Temperatura reduzida (0.5) para respostas mais diretas

### 3. Monitoramento

**ImportÃ¢ncia**:
- Essencial para entender custos e performance
- Permite otimizaÃ§Ãµes baseadas em dados reais
- Facilita debugging de problemas

**ImplementaÃ§Ã£o**:
- Callback LangChain para captura automÃ¡tica
- Armazenamento no banco para anÃ¡lise histÃ³rica
- Logs estruturados para observabilidade

### 4. Rate Limiting

**Necessidade**:
- Groq API tem limite de 30 RPM (free tier)
- Protege contra uso excessivo
- Evita custos inesperados

**ImplementaÃ§Ã£o**:
- `slowapi` para rate limiting
- Por usuÃ¡rio autenticado (fallback para IP)
- Em memÃ³ria (pode migrar para Redis em produÃ§Ã£o)

### 5. PrevenÃ§Ã£o de AlucinaÃ§Ã£o

**EstratÃ©gias**:
- ValidaÃ§Ã£o pÃ³s-resposta contra contexto
- ExtraÃ§Ã£o e validaÃ§Ã£o de nomes de restaurantes
- Fallback para respostas genÃ©ricas
- Guardrails no prompt

### 6. UX e InteraÃ§Ãµes Sociais

**Descoberta**:
- LLM nÃ£o Ã© necessÃ¡rio para interaÃ§Ãµes simples
- Respostas prÃ©-definidas sÃ£o mais rÃ¡pidas e naturais
- Bypass do LLM para saudaÃ§Ãµes, agradecimentos, despedidas

**ImplementaÃ§Ã£o**:
- `detect_social_interaction()` antes do LLM
- Respostas variadas e naturais
- Reduz latÃªncia e custo

### 7. Testes E2E

**Desafios**:
- Playwright requer login
- Seletores precisam ser robustos
- Timing Ã© crÃ­tico (aguardar LLM)

**SoluÃ§Ãµes**:
- Helpers reutilizÃ¡veis (`ensureLoggedIn`, `openChefVirtual`)
- Timeouts adequados (15s para respostas LLM)
- Seletores especÃ­ficos (scoped dentro de `[role="dialog"]`)

---

## ğŸ“– ReferÃªncias

### DocumentaÃ§Ã£o

- [LangChain Documentation](https://python.langchain.com/)
- [PGVector](https://github.com/pgvector/pgvector)
- [Groq API](https://console.groq.com/docs)
- [FastAPI](https://fastapi.tiangolo.com/)
- [Playwright](https://playwright.dev/)

### Arquivos do Projeto

- `tastematch/Docs/chef-virtual.md` - Plano de implementaÃ§Ã£o original
- `tastematch/Docs/STATUS-CHEF-VIRTUAL.md` - Status detalhado do projeto
- `tastematch/backend/test_monitoring.py` - Script de teste de monitoramento

### CÃ³digo Principal

- `backend/app/core/chef_chat.py` - LÃ³gica do Chef Virtual
- `backend/app/core/rag_service.py` - ServiÃ§o RAG
- `backend/app/core/llm_monitoring.py` - Monitoramento LLM
- `frontend/src/components/features/ChefChat.tsx` - Componente de chat

---

## ğŸ¯ PrÃ³ximos Passos (Opcional)

### Melhorias Futuras

1. **Cache de Respostas**: Reduzir chamadas LLM para perguntas frequentes
2. **Redis para Rate Limiting**: Compartilhar limite entre instÃ¢ncias
3. **Retry com Backoff**: Melhorar resiliÃªncia para erros 429
4. **Dashboard de MÃ©tricas**: VisualizaÃ§Ã£o grÃ¡fica de mÃ©tricas
5. **Alertas**: NotificaÃ§Ãµes para latÃªncia alta ou erros
6. **Multi-idioma**: Suporte a outros idiomas alÃ©m de portuguÃªs

### Testes Pendentes

- Testes E2E de Ã¡udio (requer permissÃµes de microfone)
- Testes de carga (stress testing)
- Testes de integraÃ§Ã£o com diferentes modelos LLM

---

**Ãšltima AtualizaÃ§Ã£o**: 2025-01-XX  
**Mantenedor**: Equipe TasteMatch

