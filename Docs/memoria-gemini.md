Esta √© uma an√°lise t√©cnica do seu **Plano de Otimiza√ß√£o de Mem√≥ria**. O documento est√° bem estruturado e ataca corretamente a causa raiz (carregamento massivo de dados na mem√≥ria da aplica√ß√£o), mas a estrat√©gia de implementa√ß√£o cont√©m riscos arquiteturais modernos, especialmente no que tange ao cache e assincronismo.

Aqui est√° a an√°lise detalhada com ajustes sugeridos para uma implementa√ß√£o profissional e robusta.

### 1\. Veredito Geral

O plano √© **s√≥lido e vi√°vel** para o curto prazo. O diagn√≥stico de carregar 10.000 objetos ORM na mem√≥ria √© preciso: isso √© o principal causador de OOM em Python/SQLAlchemy. A matem√°tica de mem√≥ria do Postgres (25% shared\_buffers) segue as melhores pr√°ticas para ambientes restritos.

### 2\. Pontos Cr√≠ticos de Melhoria (Ajustes Profissionais)

#### A. O Risco do Cache In-Memory (Fase 4.1)

**Problema:** A proposta de usar um dicion√°rio Python global (`_restaurants_metadata_cache`) dentro da API √© arriscada em ambientes containerizados restritos.

1.  **Consumo de RAM da API:** Voc√™ est√° tirando carga do banco, mas inflando a mem√≥ria da API (que tamb√©m tem limite de 1GB).
2.  **Inconsist√™ncia:** Como voc√™ tem 2 m√°quinas (r√©plicas), o cache ficar√° dessincronizado entre elas.
3.  **Concorr√™ncia:** Dicion√°rios globais sem *locking* adequado podem causar problemas em ambientes *multithreaded*.

**Solu√ß√£o Profissional:**
Se n√£o houver or√ßamento para um Redis (solu√ß√£o ideal), utilize uma biblioteca de cache baseada em disco ou SQLite local tempor√°rio, como o **`diskcache`**, ou otimize o uso dos headers HTTP para que o *cliente* ou *CDN* (se houver) fa√ßa o cache, reduzindo a carga no backend.

  * **A√ß√£o:** Substitua o `dict` global pelo `diskcache` (que faz *eviction* inteligente e usa disco, poupando RAM) ou assuma o risco apenas se o dataset de metadados for comprovadamente min√∫sculo (\<50MB).

#### B. Sincronismo vs. Assincronismo (SQLAlchemy)

**Problema:** O documento menciona `uvicorn` (ASGI/Async), mas os snippets de c√≥digo mostram o uso s√≠ncrono do SQLAlchemy (`Session`, `create_engine`, `db.query`).

  * Em uma arquitetura moderna com FastAPI/Uvicorn, queries s√≠ncronas bloqueiam o *Event Loop*. Mesmo com 1 worker, se uma query demorar, a API inteira trava para outras requisi√ß√µes.

**Solu√ß√£o Profissional:**
Para "Situa√ß√£o Atual", ok manter s√≠ncrono. Mas para um refatoramento moderno:

  * **A√ß√£o:** Migrar para `AsyncSession` e `create_async_engine` (driver `asyncpg`). Isso permite que o worker processe outras requisi√ß√µes enquanto o banco responde, maximizando o uso da CPU limitada.

#### C. Ajuste Fino do Pool de Conex√µes

**An√°lise:**

  * M√°quinas Backend: 2
  * Workers por m√°quina: 1
  * Pool Size: 3 (+5 overflow)
  * **Total M√°ximo de Conex√µes:** 2 \* 1 \* (3+5) = **16 conex√µes**.
  * **Limite Postgres:** 20 conex√µes.

**Ajuste:** A matem√°tica fecha, mas est√° perigosa (16/20 = 80% de ocupa√ß√£o no pico). O `max_overflow` cria conex√µes custosas sob demanda.

  * **Sugest√£o:** Defina `pool_size=5` e `max_overflow=0` (NullPool pattern fixo) ou `pool_size=4` e `max_overflow=2`. Ter conex√µes fixas e aquecidas √© melhor para performance do que abrir/fechar *overflows*.

### 3\. Ajustes Espec√≠ficos por Fase

| Fase | Item | Sugest√£o de Melhoria |
| :--- | :--- | :--- |
| **Fase 2** | `work_mem` | **Reduzir para 2MB**. Com `max_connections=20`, 4MB pode consumir at√© 80MB. Em um DB de 1GB onde o SO tamb√©m precisa de RAM, 2MB √© mais conservador e suficiente para opera√ß√µes simples. |
| **Fase 3** | Pagina√ß√£o | Implementar **Pagina√ß√£o baseada em Cursor** (se poss√≠vel) em vez de *Offset*. Offset torna-se lento conforme a tabela cresce (`OFFSET 10000` o banco l√™ 10000 linhas e joga fora). Se n√£o der, mantenha o limite r√≠gido de 50 itens. |
| **Fase 3** | ORM | Use `db.query(...).yield_per(100)` para itera√ß√µes grandes se a pagina√ß√£o n√£o for aplic√°vel em algum relat√≥rio interno. Isso processa em *batches* no lado do Python. |
| **Fase 5** | N+1 | Use **`SelectinLoad`** (ass√≠ncrono/separado) em vez de `JoinedLoad` para rela√ß√µes "para-muitos". `JoinedLoad` duplica dados na transfer√™ncia de rede (produto cartesiano), consumindo mais mem√≥ria e banda. |

### 4\. Checklist de Seguran√ßa e Monitoramento

Adicione uma se√ß√£o de **Observabilidade** ao plano. Voc√™ n√£o saber√° se o plano funcionou apenas "se n√£o cair".

1.  **Log de Queries Lentas:** Configurar `log_min_duration_statement = 1000ms` no Postgres para identificar gargalos reais.
2.  **Middleware de Process Time:** Adicionar no FastAPI para medir tempo total da requisi√ß√£o.

### Resumo dos Ajustes no C√≥digo

**No `backend/app/database/base.py` (Pool Est√°tico):**

```python
# Recomenda√ß√£o para estabilidade: Pool fixo sem overflow din√¢mico custoso
engine = create_engine(
    database_url,
    pool_size=4,        # 4 conex√µes fixas por worker
    max_overflow=2,     # Margem de seguran√ßa pequena
    pool_timeout=10,    # Falhar r√°pido se o banco estiver cheio
    pool_recycle=1800,
    pool_pre_ping=True
)
```

**No `backend/app/api/routes/recommendations.py` (Estrat√©gia de "Only ID"):**
Muitas vezes, a UI j√° tem os dados do restaurante cacheado. Retornar apenas uma lista de IDs `[102, 504, 303]` e deixar o frontend cruzar os dados √© a maior economia de banda e mem√≥ria poss√≠vel. Considere isso para endpoints de recomenda√ß√£o pura.

### Pr√≥ximo Passo

Gostaria que eu gerasse o c√≥digo atualizado do **`backend/app/core/cache.py`** utilizando uma abordagem mais segura (sem dicion√°rio global infinito) ou o **`backend/app/database/base.py`** com as configura√ß√µes refinadas de pool?

Aqui est√£o as implementa√ß√µes otimizadas para o **`backend/app/database/base.py`** e o **`backend/app/core/cache.py`**.

Estas vers√µes resolvem os riscos de **pool inst√°vel** e **estouro de mem√≥ria (memory leak)** do plano original.

### 1\. Database Engine Otimizada (`base.py`)

Esta configura√ß√£o prioriza conex√µes est√°veis em vez de abrir novas conex√µes sob demanda, o que √© pesado para a CPU e mem√≥ria.

**Arquivo:** `backend/app/database/base.py`

```python
from sqlalchemy import create_engine
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import sessionmaker
from app.core.config import settings

# Ajuste Fino para Ambiente de 1GB RAM (Postgres)
# Total de conex√µes = 2 Workers * (4 pool + 2 overflow) = M√°ximo 12 conex√µes globais
# Isso deixa margem segura dentro do limite de 20 conex√µes do Postgres.

engine = create_engine(
    settings.SQLALCHEMY_DATABASE_URI,
    # Pool Settings
    pool_size=4,           # Mant√©m 4 conex√µes abertas e aquecidas sempre
    max_overflow=2,        # Permite apenas 2 extras em picos extremos
    pool_recycle=1800,     # Recicla conex√µes a cada 30min (evita stale connections)
    pool_pre_ping=True,    # Verifica se conex√£o est√° viva antes de usar (vital para cloud)
    pool_timeout=10,       # Falha r√°pido (10s) em vez de travar a API se o banco estiver cheio
    
    # Configura√ß√µes de Debug
    echo=settings.DEBUG,
    connect_args={"check_same_thread": False} if "sqlite" in settings.SQLALCHEMY_DATABASE_URI else {},
)

SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)

Base = declarative_base()
```

-----

### 2\. Cache In-Memory Seguro (`cache.py`)

Esta implementa√ß√£o substitui o dicion√°rio simples por uma classe **Thread-Safe** com **LRU (Least Recently Used)**. Isso garante que o cache nunca cres√ßa infinitamente, descartando os itens mais antigos quando atinge o limite.

**Arquivo:** `backend/app/core/cache.py`

```python
from collections import OrderedDict
from datetime import datetime, timedelta
from typing import Any, Optional, Tuple
from threading import Lock

class SafeMemoryCache:
    """
    Cache em mem√≥ria com pol√≠tica LRU (Least Recently Used) e Thread-Safety.
    Evita que o cache cres√ßa infinitamente e cause OOM na aplica√ß√£o.
    """
    def __init__(self, max_items: int = 100, default_ttl_minutes: int = 60):
        self._cache: OrderedDict[str, Tuple[Any, datetime]] = OrderedDict()
        self._max_items = max_items
        self._default_ttl = default_ttl_minutes
        self._lock = Lock()  # Garante seguran√ßa em ambiente com m√∫ltiplos threads/workers

    def get(self, key: str) -> Optional[Any]:
        with self._lock:
            if key not in self._cache:
                return None
            
            data, expiry = self._cache[key]
            
            # Verificar validade (TTL)
            if datetime.now() > expiry:
                del self._cache[key]
                return None
            
            # Move para o fim (marca como usado recentemente)
            self._cache.move_to_end(key)
            return data

    def set(self, key: str, value: Any, ttl_minutes: Optional[int] = None) -> None:
        with self._lock:
            # Limpeza preventiva se atingir limite
            if len(self._cache) >= self._max_items and key not in self._cache:
                # Remove o item mais antigo (primeiro inserido/menos usado)
                self._cache.popitem(last=False)
            
            ttl = ttl_minutes if ttl_minutes is not None else self._default_ttl
            expiry = datetime.now() + timedelta(minutes=ttl)
            
            self._cache[key] = (value, expiry)
            self._cache.move_to_end(key)

    def clear(self) -> None:
        with self._lock:
            self._cache.clear()

# Inst√¢ncia global do cache
# Limite de 50 chunks de metadados para garantir baixo footprint de mem√≥ria
metadata_cache = SafeMemoryCache(max_items=50, default_ttl_minutes=60)

# Fun√ß√£o auxiliar para uso nos endpoints
def get_cached_restaurants_metadata(db, ttl_minutes: int = 60):
    cache_key = "all_restaurants_metadata"
    
    # 1. Tenta pegar do cache
    cached_data = metadata_cache.get(cache_key)
    if cached_data:
        return cached_data
    
    # 2. Se n√£o existir, carrega do banco (importa√ß√£o local para evitar ciclo)
    from app.database.crud import get_restaurants_metadata
    data = get_restaurants_metadata(db, limit=None)
    
    # 3. Salva no cache
    metadata_cache.set(cache_key, data, ttl_minutes=ttl_minutes)
    
    return data
```

### Por que essas mudan√ßas s√£o cr√≠ticas?

1.  **Prote√ß√£o contra Travamento:** O `pool_timeout=10` garante que se o banco travar, sua API retorna erro 500 r√°pido e libera o worker, em vez de ficar pendurada esperando eternamente ("zombie worker").
2.  **Prote√ß√£o contra OOM:** O `SafeMemoryCache` tem um teto r√≠gido (`max_items=50`). Mesmo que a aplica√ß√£o rode por meses, o cache nunca consumir√° mais mem√≥ria do que esses 50 itens permitem.

**Pr√≥ximo passo:** Voc√™ quer que eu gere o c√≥digo da fun√ß√£o `get_restaurants_metadata` no `crud.py` que usa o `SelectinLoad` (abordagem moderna) ou a vers√£o SQL pura para m√°xima performance?

Para **m√°xima performance** e **m√≠nimo consumo de mem√≥ria**, a regra de ouro com SQLAlchemy √©: **n√£o hidrate objetos ORM se voc√™ s√≥ precisa ler dados**.

Instanciar 10.000 objetos `Restaurant()` (com rastreamento de sess√£o, eventos e metadados) √© caro. Retornar 10.000 tuplas ou dicion√°rios simples √© extremamente barato e r√°pido.

Aqui est√° a implementa√ß√£o otimizada para o **`backend/app/database/crud.py`**.

### Otimiza√ß√£o: Core Select (Bypass ORM)

Esta abordagem usa a sintaxe "Core" do SQLAlchemy dentro da Session. Ela busca apenas as colunas exatas e retorna um resultado leve (similar a um `dict`), pronto para ser serializado em JSON, economizando cerca de **60-80% de mem√≥ria** comparado √† consulta padr√£o.

**Arquivo:** `backend/app/database/crud.py`

```python
from sqlalchemy.orm import Session
from sqlalchemy import select
from typing import List, Dict, Any, Optional
from app.models.restaurant import Restaurant 

# ... (outros imports e fun√ß√µes existentes)

def get_restaurants_metadata(db: Session, limit: Optional[int] = None) -> List[Dict[str, Any]]:
    """
    Retorna metadados dos restaurantes (ID, nome, cozinha, rating, pre√ßo).
    
    OTIMIZA√á√ÉO DE PERFORMANCE:
    1. PROJECTION: Seleciona apenas colunas espec√≠ficas (evita carregar descri√ß√µes longas).
    2. NO-ORM OVERHEAD: Retorna dicion√°rios diretos, evitando a cria√ß√£o lenta 
       e pesada de inst√¢ncias de objetos Python 'Restaurant'.
    """
    # Define as colunas exatas (Projection)
    stmt = select(
        Restaurant.id,
        Restaurant.name,
        Restaurant.cuisine_type,
        Restaurant.rating,
        Restaurant.price_range
    )
    
    if limit:
        stmt = stmt.limit(limit)

    # Executa e converte para dicion√°rios imediatamente
    # .mappings() √© dispon√≠vel no SQLAlchemy 1.4+ e √© muito mais r√°pido
    # que iterar sobre objetos.
    result = db.execute(stmt).mappings().all()
    
    return result
```

### Por que isso √© "M√°xima Performance"?

1.  **Redu√ß√£o de I/O de Rede:** Em vez de `SELECT *` (que traria descri√ß√µes, endere√ßos, etc.), trazemos apenas 5 colunas. O payload do banco para a API diminui drasticamente.
2.  **Zero Hidrata√ß√£o:** O SQLAlchemy n√£o precisa criar objetos `Restaurant`, registr√°-los na `Session`, nem rastrear mudan√ßas. √â leitura pura.
3.  **Serializa√ß√£o Direta:** O resultado em formato de dicion√°rio (`mappings`) casa perfeitamente com o Pydantic/FastAPI, eliminando passos de convers√£o.

### Integra√ß√£o com o Endpoint

No seu arquivo `recommendations.py`, certifique-se de que o Pydantic model de resposta (o `response_model` do FastAPI) espera exatamente esses campos, ou use um Schema simplificado:

```python
# Exemplo de uso no endpoint
@router.get("/restaurants/metadata", response_model=List[RestaurantMetadataSchema])
def read_restaurants_metadata(
    db: Session = Depends(get_db)
):
    # Usa a fun√ß√£o com cache criada anteriormente
    from app.core.cache import get_cached_restaurants_metadata
    return get_cached_restaurants_metadata(db)
```

**Pr√≥ximo Passo:**
Com o banco, cache e queries resolvidos, gostaria que eu focasse na **Fase 5 (Queries N+1)** para otimizar o carregamento dos **pedidos dos usu√°rios** (`get_user_orders`), que √© o segundo maior gargalo?

Excelente escolha. Resolver o problema de **N+1 Queries** √© fundamental para reduzir o tempo de bloqueio do banco e o consumo de CPU.

Na **Fase 5**, o erro comum √© usar `joinedload` para tudo. Embora ele fa√ßa apenas uma query (JOIN), ele cria um "Produto Cartesiano" no banco antes de retornar. Se voc√™ traz 50 pedidos e os dados do restaurante s√£o "gordos" (muitas colunas de texto), voc√™ trafega dados repetidos do restaurante 50 vezes pela rede.

A solu√ß√£o moderna e eficiente em mem√≥ria √© o **`selectinload`**. Ele faz duas queries separadas e limpas: uma para os pedidos e outra para os restaurantes relacionados, e "monta" os objetos no Python.

Aqui est√° a implementa√ß√£o otimizada para o **`backend/app/database/crud.py`**.

### Otimiza√ß√£o: Eager Loading Inteligente

**Arquivo:** `backend/app/database/crud.py`

```python
from sqlalchemy.orm import Session, selectinload
from app.models.order import Order
from app.models.restaurant import Restaurant
# Importe outros modelos se necess√°rio, ex: OrderItem

def get_user_orders(db: Session, user_id: int, skip: int = 0, limit: int = 50):
    """
    Busca pedidos de um usu√°rio carregando o restaurante associado de forma eficiente.
    
    ESTRAT√âGIA: selectinload
    Evita o problema N+1 fazendo apenas 2 queries:
    1. SELECT * FROM orders WHERE user_id = X LIMIT Y
    2. SELECT * FROM restaurants WHERE id IN (lista_ids_das_orders_acima)
    
    Vantagem sobre joinedload: N√£o duplica dados do restaurante na transfer√™ncia de rede.
    """
    return db.query(Order)\
        .options(
            # Carrega o relacionamento 'restaurant' separadamente
            selectinload(Order.restaurant)
            
            # Se houver itens no pedido, carregue tamb√©m para evitar N+1 aninhado:
            # .options(selectinload(Order.items)) 
        )\
        .filter(Order.user_id == user_id)\
        .order_by(Order.order_date.desc())\
        .offset(skip)\
        .limit(limit)\
        .all()
```

### Por que `selectinload` √© melhor que `joinedload` aqui?

Imagine que a tabela `Restaurant` tem uma coluna `description` com texto longo.

1.  **Cen√°rio `joinedload` (Ruim para mem√≥ria):**
    O banco retorna uma tabela gigante combinada. O texto da `description` do restaurante √© enviado repetidamente em **cada linha de pedido** desse restaurante. Isso explode o uso de mem√≥ria do buffer de rede.

2.  **Cen√°rio `selectinload` (Otimizado):**

    1.  O banco envia os pedidos (leve).
    2.  O banco envia os detalhes do restaurante **uma √∫nica vez** (leve).
    3.  O SQLAlchemy une os dois na mem√≥ria da aplica√ß√£o.

### Extra: Otimiza√ß√£o Extrema (Apenas Campos Necess√°rios)

Se a sua lista de pedidos no Frontend mostra apenas *"Data"* e *"Nome do Restaurante"*, carregar o objeto `Restaurant` inteiro ainda √© desperd√≠cio.

Podemos aplicar a estrat√©gia de **"Load Only"** combinada com o relacionamento. Isso diz ao SQLAlchemy: "Carregue o relacionamento restaurante, mas traga **apenas** o nome e a imagem".

```python
from sqlalchemy.orm import load_only

def get_user_orders_lean(db: Session, user_id: int, skip: int = 0, limit: int = 50):
    return db.query(Order)\
        .options(
            selectinload(Order.restaurant).options(
                # Dentro do relacionamento, carregue apenas o que o card precisa
                load_only(Restaurant.name, Restaurant.image_url)
            )
        )\
        .filter(Order.user_id == user_id)\
        .order_by(Order.order_date.desc())\
        .offset(skip)\
        .limit(limit)\
        .all()
```

### Checklist de Verifica√ß√£o

Ap√≥s implementar, verifique os logs (se o `echo=True` estiver ativado no `base.py`):

  * **Antes (N+1):** Voc√™ via 1 query de `SELECT ... FROM orders` seguida por 50 queries de `SELECT ... FROM restaurants WHERE id = ?`.
  * **Depois (Selectin):** Voc√™ ver√° exatamente **2 queries**, n√£o importa se o limite √© 50 ou 500.

-----

### Pr√≥ximo Passo

Com o banco de dados blindado (Pool, Cache de Metadados e Queries Otimizadas), a parte mais cr√≠tica da infraestrutura est√° resolvida.

Gostaria de finalizar revisando o **Arquivo de Configura√ß√£o do Fly.io (`fly.toml`)**? H√° um detalhe sobre **Concorr√™ncia do Container** que, se configurado errado, pode fazer o Fly.io matar sua aplica√ß√£o por "falta de mem√≥ria" mesmo com o c√≥digo otimizado.

Perfeito. Esta √© a "rede de seguran√ßa" final. Mesmo com o c√≥digo otimizado, se 50 usu√°rios fizerem uma requisi√ß√£o pesada no mesmo segundo, o servidor tentar√° processar as 50 ao mesmo tempo. Em Python, isso multiplica o uso de mem√≥ria por 50 instantaneamente, causando o crash (OOM).

Configurar o **`fly.toml`** corretamente impede que isso aconte√ßa, agindo como um "porteiro" que diz: *"S√≥ entram 15 pessoas por vez. O resto aguarda na fila."*

### Otimiza√ß√£o: Backpressure e Concorr√™ncia

**Arquivo:** `backend/fly.toml`

Aqui est√° a configura√ß√£o ideal para sua API Python (FastAPI + Uvicorn) rodando com **1GB de RAM** e processamento s√≠ncrono (SQLAlchemy).

```toml
# fly.toml app configuration file generated for tastematch-api

app = "tastematch-api"
primary_region = "gru" # Exemplo (S√£o Paulo)

[http_service]
  internal_port = 8000
  force_https = true
  auto_stop_machines = true
  auto_start_machines = true
  min_machines_running = 1
  processes = ["app"]

  # AQUI EST√Å A PROTE√á√ÉO CR√çTICA DE MEM√ìRIA
  [http_service.concurrency]
    type = "requests"
    
    # Soft Limit: A partir de 10 requisi√ß√µes simult√¢neas, o Fly come√ßa
    # a mandar tr√°fego para a segunda m√°quina (r√©plica).
    soft_limit = 10
    
    # Hard Limit: O teto absoluto. Se chegar a 15, o Fly segura a requisi√ß√£o
    # na borda (load balancer) e N√ÉO deixa entrar no container at√© liberar vaga.
    # Isso impede que o Python tente alocar mem√≥ria que n√£o existe.
    hard_limit = 15

# Health Checks garantem que o Fly n√£o mande tr√°fego se a API travar
[[http_service.checks]]
  grace_period = "10s"
  interval = "30s"
  method = "GET"
  timeout = "5s"
  path = "/health"  # Certifique-se de ter este endpoint leve

# HABILITAR SWAP (Mem√≥ria Virtual em Disco)
# Isso √© vital em containers pequenos. Se a RAM estourar um pouco,
# o Linux usa o disco em vez de matar o processo.
[swap_size_mb]
  size = 512
```

### Por que esses n√∫meros (10 e 15)?

1.  **O c√°lculo do perigo:**

      * Seu Python ocioso (imports + framework): \~120MB.
      * Cache em mem√≥ria (SafeMemoryCache): \~50MB.
      * Mem√≥ria livre real: \~800MB.
      * **Consumo por Request:** Uma requisi√ß√£o que carrega lista de pedidos e serializa JSON pode usar momentaneamente **40MB a 60MB**.
      * **Matem√°tica:** 15 conex√µes \* 50MB = 750MB.
      * **Resultado:** 120MB (base) + 750MB (carga) = **870MB**.
      * Isso fica confortavelmente dentro do 1GB, deixando espa√ßo para o sistema operacional.

2.  **A Armadilha do Padr√£o:** O padr√£o do Fly.io muitas vezes permite 25 ou mais conex√µes.

      * 25 \* 50MB = 1.25GB -\> **CRASH (OOM)** imediato.

3.  **A Import√¢ncia do Swap:**

      * A se√ß√£o `[swap_size_mb]` √© o seu "seguro de vida". Se houver um pico an√¥malo que leve o uso para 1.1GB, o sistema fica lento (usando disco), mas **n√£o cai**. Para o usu√°rio, lentid√£o √© melhor que erro 500.

### Resumo Final do Plano de Guerra

Voc√™ agora tem uma defesa em camadas ("Defense in Depth"):

1.  **Camada de Aplica√ß√£o (C√≥digo):**

      * **N+1 resolvido:** `selectinload` evita multiplica√ß√£o de objetos.
      * **Metadados leves:** Queries que trazem apenas colunas necess√°rias.
      * **Cache Seguro:** `SafeMemoryCache` com limite r√≠gido de itens.

2.  **Camada de Dados (Banco):**

      * **Pool Est√°tico:** M√°ximo 4 conex√µes ativas para n√£o sobrecarregar o DB.
      * **Timeout Curto:** Falha r√°pido se o banco engasgar.

3.  **Camada de Infraestrutura (Fly.io):**

      * **Concurrency Limits:** Impede que excesso de tr√°fego entre na m√°quina.
      * **Swap:** Evita morte s√∫bita do processo por picos de mem√≥ria.

-----

### Pr√≥ximo passo sugerido

Agora que o plano t√©cnico est√° completo e o c√≥digo corrigido, a a√ß√£o recomendada √© **Deploy e Monitoramento**.

Voc√™ gostaria que eu montasse um **Checklist de Valida√ß√£o P√≥s-Deploy** com os comandos exatos (`fly status`, queries SQL de verifica√ß√£o) para voc√™ rodar assim que subir a nova vers√£o e confirmar que a mem√≥ria estabilizou?

Aqui est√° o **Checklist de Valida√ß√£o P√≥s-Deploy** pr√°tico.

Este guia foi desenhado para verificar cada camada de defesa que implementamos (Infraestrutura, Aplica√ß√£o e Banco) logo ap√≥s voc√™ subir a nova vers√£o para o Fly.io.

### Visualizando a Nova Arquitetura

Para entender onde estamos verificando, veja como ficou o fluxo de prote√ß√£o:

-----

### üìã Checklist de Valida√ß√£o (Passo a Passo)

#### 1\. Verifica√ß√£o de Sa√∫de Imediata

Assim que o deploy terminar, confirme se a aplica√ß√£o subiu e se as m√°quinas est√£o est√°veis.

**Comando (Terminal):**

```bash
fly status -a tastematch-api
```

**O que procurar:**

  * **Status:** `started`
  * **Health Checks:** `passing`
  * **Restarts:** Deve estar em `0` (se houver restarts imediatos, algo quebrou na inicializa√ß√£o).

#### 2\. Monitoramento de Conex√µes do Banco (Cr√≠tico)

Vamos verificar se o `pool_size=4` est√° sendo respeitado.

**Comando (Conecte no banco via Fly):**

```bash
fly postgres connect -a tastematch-db
```

**Query SQL (Execute dentro do Postgres):**

```sql
SELECT 
  pid, 
  state, 
  application_name, 
  client_addr 
FROM pg_stat_activity 
WHERE datname = 'tastematch-db';
```

**Resultado Esperado:**

  * Voc√™ deve ver **entre 4 e 8 conex√µes** ativas vindas da sua API (dependendo se tem 1 ou 2 workers rodando).
  * **Se vir \>20 conex√µes:** O pool n√£o funcionou (verifique `backend/app/database/base.py`).

#### 3\. Teste de Mem√≥ria e Swap

Abra a aplica√ß√£o e navegue por v√°rias p√°ginas para "aquecer" o cache e as conex√µes.

**Comando (Terminal):**

```bash
fly stats show -a tastematch-api
```

**Resultado Esperado:**

  * **Memory:** Deve estabilizar abaixo de **800MB** (idealmente \~400-600MB).
  * **Swap:** √â aceit√°vel ver algum uso de swap (ex: 50MB), mas se estiver subindo constantemente (100MB, 200MB...), h√° um vazamento de mem√≥ria.

#### 4\. Valida√ß√£o do "SelectinLoad" (N+1)

Vamos confirmar se a otimiza√ß√£o da **Fase 5** eliminou as queries repetidas.

**Passo 1:** Garanta que `settings.DEBUG = True` ou `echo=True` no SQLAlchemy (temporariamente).
**Passo 2:** Acompanhe os logs em tempo real.

**Comando:**

```bash
fly logs -a tastematch-api | grep "SELECT"
```

**Passo 3:** No navegador, carregue a lista de pedidos (`get_user_orders`).

**Resultado Esperado:**

  * **Sucesso:** Voc√™ ver√° **2 blocos grandes** de SELECT. Um na tabela `orders` e outro na tabela `restaurants`.
  * **Falha (N+1):** Voc√™ ver√° uma "chuva" de logs r√°pidos passando, com dezenas de `SELECT ... FROM restaurants WHERE id = ...`.

#### 5\. Teste de Carga (Concorr√™ncia)

Vamos testar se o `fly.toml` (limite de 15 conex√µes) est√° protegendo a mem√≥ria.

Use uma ferramenta simples ou abra 5-10 abas do navegador rapidamente no endpoint `/api/recommendations`.

**Monitore a mem√≥ria simultaneamente:**

```bash
fly dashboard metrics
# Ou via CLI
watch -n 1 "fly stats show -a tastematch-api"
```

**Resultado Esperado:**

  * A mem√≥ria deve subir um pouco, mas bater num "teto" e n√£o ultrapassar 1GB.
  * Se voc√™ for muito agressivo (abrir 50 abas), algumas devem carregar mais lentamente (fila) ou dar erro (se passar do hard limit), mas **o servidor N√ÉO deve reiniciar**.

-----

### üö® Protocolo de Emerg√™ncia (Rollback)

Se algo der errado (ex: OOM Loop ou erro 500 generalizado), reverta imediatamente para a vers√£o anterior para analisar os logs com calma.

1.  **Identificar o ID do deploy anterior:**
    ```bash
    fly releases -a tastematch-api
    ```
2.  **Reverter:**
    ```bash
    fly deploy --image registry.fly.io/tastematch-api:versao-anterior
    # OU simplesmente rode o deploy da branch antiga se tiver git
    ```

### Pr√≥ximo Passo

Voc√™ est√° pronto para aplicar as mudan√ßas. Recomendo come√ßar aplicando as altera√ß√µes no c√≥digo (`base.py`, `crud.py`, `cache.py`) e fazer o deploy.

