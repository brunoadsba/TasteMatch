"""
PÃ³s-processamento de resposta para aplicar formataÃ§Ã£o visual
quando o LLM nÃ£o segue as instruÃ§Ãµes de formataÃ§Ã£o
"""

import re
from typing import List, Dict, Any, Optional
from langchain_core.documents import Document


def get_cuisine_emoji(cuisine_type: str) -> str:
    """
    Retorna emoji contextualmente relevante baseado no tipo de culinÃ¡ria.
    FASE 5: Mapeamento centralizado com correspondÃªncia parcial para cobrir variaÃ§Ãµes.
    
    Args:
        cuisine_type: Tipo de culinÃ¡ria (ex: "italiana", "pizzaria", "japonesa")
    
    Returns:
        Emoji correspondente ou emoji padrÃ£o se nÃ£o encontrado
    """
    if not cuisine_type:
        return "ğŸ½ï¸"  # Default genÃ©rico
    
    c_lower = cuisine_type.lower()
    
    # DicionÃ¡rio de mapeamento (ordem importa: termos mais especÃ­ficos primeiro)
    emoji_map = {
        "pizza": "ğŸ•",
        "hambÃºrguer": "ğŸ”",
        "burger": "ğŸ”",
        "americana": "ğŸ”",
        "japonesa": "ğŸ£",
        "sushi": "ğŸ£",
        "oriental": "ğŸ¥¢",
        "italiana": "ğŸ",
        "massa": "ğŸ",
        "brasileira": "ğŸ‡§ğŸ‡·",
        "feijoada": "ğŸ›",
        "mexicana": "ğŸŒ®",
        "taco": "ğŸŒ®",
        "churrasco": "ğŸ¥©",
        "churrascaria": "ğŸ¥©",
        "carne": "ğŸ¥©",
        "vegetariana": "ğŸ¥—",
        "vegana": "ğŸŒ¿",
        "saudÃ¡vel": "ğŸ¥‘",
        "salada": "ğŸ¥—",
        "cafÃ©": "â˜•",
        "cafeteria": "â˜•",
        "padaria": "ğŸ¥",
        "doce": "ğŸ°",
        "sobremesa": "ğŸ¨",
        "sorvete": "ğŸ¦",
        "frutos do mar": "ğŸ¦",
        "peixe": "ğŸŸ",
        "arabe": "ğŸ¥™",
        "Ã¡rabe": "ğŸ¥™",
        "libanesa": "ğŸ¥™",
        "chinesa": "ğŸ¥¡",
        "indiana": "ğŸ›",
        "francesa": "ğŸ¥–",
        "bebida": "ğŸ¹",
        "bar": "ğŸº",
        "hamburgueria": "ğŸ”",
        "pizzaria": "ğŸ•",
    }
    
    # Verificar correspondÃªncia parcial
    for key, emoji in emoji_map.items():
        if key in c_lower:
            return emoji
    
    return "ğŸ½ï¸"  # Fallback


def apply_visual_formatting(
    answer: str,
    source_documents: List[Document],
    question: str
) -> str:
    """
    Aplica formataÃ§Ã£o visual e REMOVE o texto original duplicado.
    FASE 3: RemoÃ§Ã£o destrutiva de parÃ¡grafos descritivos antes de adicionar cards.
    
    Detecta restaurantes mencionados e aplica formataÃ§Ã£o completa:
    - Emojis de culinÃ¡ria
    - Separadores visuais
    - PreÃ§o formatado
    - LocalizaÃ§Ã£o
    - Destaque Ãºnico
    - Rating formatado
    
    Args:
        answer: Resposta do LLM
        source_documents: Documentos recuperados do RAG
        question: Pergunta original
    
    Returns:
        Resposta formatada sem duplicatas
    """
    # CORREÃ‡ÃƒO CRÃTICA: Verificar se hÃ¡ correspondÃªncia semÃ¢ntica antes de formatar
    # Se a resposta indica que nÃ£o hÃ¡ restaurantes relevantes, nÃ£o formatar documentos nÃ£o relacionados
    question_lower = question.lower()
    answer_lower = answer.lower()
    
    # Detectar se a resposta indica que nÃ£o hÃ¡ correspondÃªncia
    no_match_indicators = [
        'nÃ£o temos', 'nÃ£o tenho', 'nÃ£o encontrei', 'nÃ£o encontramos',
        'infelizmente', 'nÃ£o estÃ¡ disponÃ­vel', 'nÃ£o estÃ¡ na lista',
        'nÃ£o temos na nossa lista', 'nÃ£o tenho na minha lista'
    ]
    
    has_no_match_indicator = any(indicator in answer_lower for indicator in no_match_indicators)
    
    # Se a resposta indica que nÃ£o hÃ¡ match, verificar se os documentos sÃ£o realmente relevantes
    if has_no_match_indicator:
        # Verificar se algum documento tem correspondÃªncia semÃ¢ntica com a pergunta
        question_keywords = set([w.lower() for w in question_lower.split() if len(w) > 2])
        has_relevant_doc = False
        
        for doc in source_documents:
            metadata = doc.metadata if hasattr(doc, 'metadata') else {}
            if metadata.get('type') == 'restaurant':
                name = metadata.get('name', '').lower()
                keywords = metadata.get('keywords', '').lower()
                description = (metadata.get('description', '') or '').lower()
                cuisine = metadata.get('cuisine_type', '').lower()
                
                # Verificar correspondÃªncia com palavras-chave da pergunta
                doc_text = f"{name} {keywords} {description} {cuisine}"
                if any(kw in doc_text for kw in question_keywords if len(kw) > 3):
                    has_relevant_doc = True
                    break
        
        # Se nÃ£o hÃ¡ documento relevante, nÃ£o formatar (retornar resposta original limpa)
        if not has_relevant_doc:
            # Limpar erros de portuguÃªs e textos incompletos antes de retornar
            cleaned_no_match = answer
            # Remover frases problemÃ¡ticas
            problematic_patterns = [
                r'(?i)No\s+entanto,\s+posso\s+sugerir\s+algumas\s+alternativas\s+prÃ³ximas[^.]*\.\s*',
                r'(?i)posso\s+sugerir\s+algumas\s+alternativas\s+prÃ³ximas[^.]*\.\s*',
                r'(?i)Se\s+vocÃª\s+estiver\s+procurando\s+por\s+algo\s+semelhante[^.]*\.\s*',
                r'(?i)eu\s+recomendaria\s+o\s+de\s+ou\s+a[^.]*\.\s*',
                r'(?i)recomendaria\s+o\s+de\s+ou\s+a[^.]*\.\s*',
                r'(?i)recomendaria\s+o\s+de[^.]*\.\s*',
                r'(?i)recomendaria\s+a\s+de[^.]*\.\s*',
            ]
            for pattern in problematic_patterns:
                cleaned_no_match = re.sub(pattern, '', cleaned_no_match, flags=re.IGNORECASE)
            # Limpar espaÃ§os duplos e pontuaÃ§Ã£o duplicada
            cleaned_no_match = re.sub(r'\s{2,}', ' ', cleaned_no_match)
            cleaned_no_match = re.sub(r'\.\s*\.', '.', cleaned_no_match)
            cleaned_no_match = cleaned_no_match.strip()
            return cleaned_no_match
    
    # 1. Identificar quais restaurantes foram citados
    restaurant_mentions = extract_restaurant_mentions(answer, source_documents)
    
    if not restaurant_mentions:
        return answer
    
    # 2. REMOÃ‡ÃƒO DESTRUTIVA: Remove trechos onde o LLM descreve o restaurante
    # para evitar que a informaÃ§Ã£o apareÃ§a duas vezes (no texto e no card)
    cleaned_answer = answer
    
    # Primeiro: remover texto introdutÃ³rio verboso antes dos restaurantes
    # CORREÃ‡ÃƒO CRÃTICA: Remover frases genÃ©ricas sobre pratos/culinÃ¡ria e erros de portuguÃªs
    verbose_patterns = [
        r'(?i)^.*?posso\s+sugerir[^.]*\.\s*',
        r'(?i)^.*?algumas\s+opÃ§Ãµes[^.]*\.\s*',
        r'(?i)^.*?restaurantes\s+listados[^.]*\.\s*',
        r'ğŸ“„\s+visitar[^.]*\.\s*',
        r'â¬†ï¸\s*ğŸ’¥\s*',
        r'(?i)^.*?No\s+entanto[^.]*\.\s*',
        # Erros de portuguÃªs e textos incompletos
        r'(?i)No\s+entanto,\s+posso\s+sugerir\s+algumas\s+alternativas\s+prÃ³ximas[^.]*\.\s*',
        r'(?i)posso\s+sugerir\s+algumas\s+alternativas\s+prÃ³ximas[^.]*\.\s*',
        r'(?i)Se\s+vocÃª\s+estiver\s+procurando\s+por\s+algo\s+semelhante[^.]*\.\s*',
        r'(?i)eu\s+recomendaria\s+o\s+de\s+ou\s+a[^.]*\.\s*',
        r'(?i)recomendaria\s+o\s+de\s+ou\s+a[^.]*\.\s*',
        r'(?i)recomendaria\s+o\s+de[^.]*\.\s*',
        r'(?i)recomendaria\s+a\s+de[^.]*\.\s*',
        # NOVO: Remover frases genÃ©ricas sobre pratos/culinÃ¡ria
        r'(?i)^\s*[A-Z][^.!?]*\s+(Ã©|sÃ£o)\s+um\s+(prato|pratos|tipo|tipos)[^.!?]*delicioso[^.!?]*!?\s*',
        r'(?i)^\s*[A-Z][^.!?]*\s+(Ã©|sÃ£o)\s+um\s+(prato|pratos|tipo|tipos)[^.!?]*tradicional[^.!?]*!?\s*',
        r'(?i)^\s*[A-Z][^.!?]*\s+(Ã©|sÃ£o)\s+um\s+(prato|pratos|tipo|tipos)[^.!?]*brasileiro[^.!?]*!?\s*',
        # Exemplo especÃ­fico: "Churrasco Ã© um prato delicioso e tradicional brasileiro!"
        r'(?i)^\s*churrasco\s+Ã©\s+um\s+prato[^.!?]*!?\s*',
        r'(?i)^\s*pizza\s+Ã©\s+um\s+prato[^.!?]*!?\s*',
        r'(?i)^\s*sushi\s+Ã©\s+um\s+prato[^.!?]*!?\s*',
    ]
    for pattern in verbose_patterns:
        cleaned_answer = re.sub(pattern, '', cleaned_answer, flags=re.MULTILINE)
    
    # Segundo: remover descriÃ§Ãµes de restaurantes mencionados
    # CORREÃ‡ÃƒO CRÃTICA: Remover cards jÃ¡ formatados pelo LLM antes de adicionar novos
    for mention in restaurant_mentions:
        name = mention["name"]
        
        # Regex melhorada: Procura o nome do restaurante seguido de qualquer texto
        # atÃ© encontrar duas quebras de linha, outro restaurante, ou fim da string
        # TambÃ©m captura variaÃ§Ãµes do nome (com/sem pontuaÃ§Ã£o)
        name_variations = [
            re.escape(name),
            re.escape(name.replace("'", "")),
            re.escape(name.replace(".", "")),
        ]
        
        for name_var in name_variations:
            # NOVO: PadrÃ£o para remover cards jÃ¡ formatados pelo LLM (com emoji, rating, etc.)
            # Exemplo: "ğŸ” **McDonald's**\nâ­ 4.0/5.0 | ğŸ’° (R$ 20-50) | ğŸ“ Centro\n..."
            formatted_card_pattern = re.compile(
                rf"[ğŸ”¥ğŸğŸ£ğŸ”ğŸ•ğŸŒ®ğŸ¥™ğŸ¦â­]?\s*\*\*{name_var}\*\*.*?(?=\n\n[ğŸ”¥ğŸğŸ£ğŸ”ğŸ•ğŸŒ®ğŸ¥™ğŸ¦â­]?\s*\*\*|â”â”|ğŸ’¡|$)",
                flags=re.IGNORECASE | re.DOTALL
            )
            cleaned_answer = re.sub(formatted_card_pattern, "", cleaned_answer)
            
            # PadrÃ£o melhorado: nome + qualquer coisa atÃ© prÃ³ximo restaurante, separador, ou fim de parÃ¡grafo
            # CORREÃ‡ÃƒO: Capturar descriÃ§Ãµes longas que incluem pontuaÃ§Ã£o e emojis
            # PadrÃ£o 1: "Nome Ã©/Ã© um/Ã© uma/tem/oferece..." seguido de descriÃ§Ã£o completa
            pattern = re.compile(
                rf"{name_var}\s+(Ã©|Ã© um|Ã© uma|tem|oferece|especializado|especializada|clÃ¡ssico|clÃ¡ssica)[^.!?]*[.!?]?\s*[ğŸ”¥â­]*.*?(?=\n\n|(?:\*\*)?[A-Z][a-z]+(?:\s+[A-Z][a-z]+)*\*\*|â”â”|\d+\.\d+/\d+\.\d+|$)", 
                flags=re.IGNORECASE | re.DOTALL
            )
            cleaned_answer = re.sub(pattern, "", cleaned_answer)
            
            # PadrÃ£o 2: "Nome Ã© um clÃ¡ssico..." seguido de descriÃ§Ã£o (mais especÃ­fico)
            pattern2 = re.compile(
                rf"{name_var}\s+Ã©\s+um\s+clÃ¡ssico[^.!?]*[.!?]?\s*[ğŸ”¥â­]*.*?(?=\n|\d+\.\d+/\d+\.\d+|$)", 
                flags=re.IGNORECASE | re.DOTALL
            )
            cleaned_answer = re.sub(pattern2, "", cleaned_answer)
            
            # PadrÃ£o 3: "Nome Ã© um clÃ¡ssico X com Y e Z. Ã‰ o lugar perfeito..." (frases compostas)
            pattern3 = re.compile(
                rf"{name_var}\s+Ã©\s+um\s+clÃ¡ssico[^.!?]*\.\s*Ã‰\s+o\s+[^.!?]*\.\s*[ğŸ”¥â­]*", 
                flags=re.IGNORECASE | re.DOTALL
            )
            cleaned_answer = re.sub(pattern3, "", cleaned_answer)
            
            # PadrÃ£o 4: Remover menÃ§Ãµes simples do nome seguido de metadados (ex: "McDonald's â­ 4.0/5.0")
            simple_mention_pattern = re.compile(
                rf"{name_var}\s+[â­ğŸ’°ğŸ“ğŸ¯].*?(?=\n\n|{name_var}|\*\*[A-Z]|$)",
                flags=re.IGNORECASE | re.DOTALL
            )
            cleaned_answer = re.sub(simple_mention_pattern, "", cleaned_answer)
    
    # Limpeza de sobras (linhas vazias extras e espaÃ§os)
    cleaned_answer = re.sub(r'\n{3,}', '\n\n', cleaned_answer)
    cleaned_answer = re.sub(r'^\s+|\s+$', '', cleaned_answer, flags=re.MULTILINE)
    cleaned_answer = cleaned_answer.strip()
    
    # CORREÃ‡ÃƒO: Remover comparaÃ§Ãµes duplicadas ou incompletas
    # Exemplo: "ComparaÃ§Ã£o: Ambos os restaurantes oferecem batata frita, mas â€”"
    comparison_patterns = [
        r'ğŸ’¡\s*\*\*ComparaÃ§Ã£o:\*\*\s*[^.]*mas\s*â€”\s*',
        r'ğŸ’¡\s*ComparaÃ§Ã£o:\s*[^.]*mas\s*â€”\s*',
        r'ComparaÃ§Ã£o:\s*[^.]*mas\s*â€”\s*',
    ]
    for pattern in comparison_patterns:
        cleaned_answer = re.sub(pattern, '', cleaned_answer, flags=re.IGNORECASE | re.MULTILINE)
    
    # Se a limpeza removeu tudo ou deixou muito pouco, restaurar intro padrÃ£o
    if len(cleaned_answer) < 15:
        cleaned_answer = "Aqui estÃ£o as opÃ§Ãµes encontradas baseadas no seu pedido:"
    
    # 3. Mapeamento de preÃ§o para texto formatado
    price_text_map = {
        "high": "ğŸ’°ğŸ’°ğŸ’° (R$ 80-120)",
        "medium": "ğŸ’°ğŸ’° (R$ 50-80)",
        "low": "ğŸ’° (R$ 20-50)"
    }
    
    # 4. Construir seÃ§Ã£o visual (cards) - usar funÃ§Ã£o centralizada de emoji
    formatted_sections = []
    
    for restaurant_info in restaurant_mentions[:3]:  # MÃ¡ximo 3
        name = restaurant_info['name']
        metadata = restaurant_info['metadata']
        
        cuisine = metadata.get('cuisine_type', '')
        rating = metadata.get('rating', '')
        price_range = metadata.get('price_range', '')
        location = metadata.get('location', '')
        
        # Usar funÃ§Ã£o centralizada de emoji (FASE 5)
        emoji = get_cuisine_emoji(cuisine)
        
        # Construir seÃ§Ã£o formatada
        section = f"{emoji} **{name}**\n"
        
        meta_parts = []
        if rating:
            meta_parts.append(f"â­ {rating}/5.0")
        if price_range and price_range in price_text_map:
            meta_parts.append(price_text_map[price_range])
        elif price_range:
            price_emoji = "ğŸ’°" if price_range == "high" else "ğŸ’µ" if price_range == "medium" else "ğŸ’¸"
            meta_parts.append(price_emoji)
        # SEMPRE incluir localizaÃ§Ã£o se disponÃ­vel (ou "NÃ£o informado" se nÃ£o tiver)
        if location:
            meta_parts.append(f"ğŸ“ {location}")
        elif not location:  # Se nÃ£o tem localizaÃ§Ã£o, nÃ£o adicionar (evitar "ğŸ“ None")
            pass
        
        if meta_parts:
            section += f"   {'  |  '.join(meta_parts)}\n"
        
        # Destaque Ãºnico
        try:
            from app.core.chef_chat import get_restaurant_highlight
            highlight = get_restaurant_highlight(metadata)
            if highlight:
                section += f"   ğŸ¯ {highlight}\n"
        except ImportError:
            # Fallback se houver problema de import circular
            pass
        
        # CORREÃ‡ÃƒO CRÃTICA: Priorizar description do metadata (fonte primÃ¡ria)
        description = metadata.get('description', '').strip()
        
        # Validar se description nÃ£o contÃ©m metadados tÃ©cnicos
        if description:
            technical_patterns = [
                r'Restaurante:\s*',
                r'Tipo de culinÃ¡ria:\s*',
                r'Tags e pratos relacionados:\s*',
                r'AvaliaÃ§Ã£o:\s*',
                r'Faixa de preÃ§o:\s*',
            ]
            has_technical = any(re.search(pattern, description, re.IGNORECASE) for pattern in technical_patterns)
            if has_technical:
                description = ""  # Rejeitar se contÃ©m formato tÃ©cnico
        
        # FALLBACK 1: Se description do metadata nÃ£o estiver disponÃ­vel, extrair da resposta
        if not description or len(description) < 20:
            description = extract_restaurant_description(answer, name, max_len=85)
        
        # FALLBACK 2: Se ainda nÃ£o houver, gerar baseado em metadados
        if not description or len(description) < 20:
            cuisine = metadata.get('cuisine_type', '')
            keywords = metadata.get('keywords', '')
            if cuisine:
                description = f"Restaurante especializado em {cuisine}"
                if keywords:
                    # Pegar primeira keyword relevante (sem tags tÃ©cnicas)
                    first_keyword = keywords.split(',')[0].strip()
                    if first_keyword and len(first_keyword) < 30:
                        description += f" com foco em {first_keyword}"
                description = description[:85]
        
        # Validar descriÃ§Ã£o final antes de usar
        if description and len(description) >= 20:
            # Limpar pontuaÃ§Ã£o solta
            description = description.rstrip(',.')
            # Aplicar blacklist conservadora (apenas se muito longa)
            if len(description) > 100:
                blacklist_patterns = [
                    r'^Ã‰ um restaurante que\s+',
                    r'^Oferece uma experiÃªncia de\s+',
                ]
                for pattern in blacklist_patterns:
                    description = re.sub(pattern, '', description, flags=re.IGNORECASE)
                description = description.strip()[:85]
            
            # Validar que nÃ£o contÃ©m palavras soltas sem sentido
            words = description.split()
            if len(words) >= 3:  # Pelo menos 3 palavras
                section += f"   {description}\n"
        
        formatted_sections.append(section)
    
    if formatted_sections:
        # SEMPRE juntar com separadores visuais
        separator = "\n\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\n"
        
        # 5. Montagem final: texto limpo + cards formatados
        formatted_cards = separator.join(formatted_sections)
        
        # Se houver apenas 1 restaurante, adicionar separador antes e depois para visibilidade
        if len(formatted_sections) == 1:
            formatted_answer = f"{cleaned_answer}\n\n{separator}{formatted_cards}{separator}"
        else:
            # Se houver mÃºltiplos, juntar com separadores entre eles
            formatted_answer = f"{cleaned_answer}\n\n{separator}{formatted_cards}{separator}"
            # Adicionar comparaÃ§Ã£o
            formatted_answer += "\n\nğŸ’¡ **ComparaÃ§Ã£o:** " + generate_comparison(restaurant_mentions[:3])
        
        return formatted_answer
    
    # Se nÃ£o houver cards, retornar resposta limpa
    return cleaned_answer


def extract_restaurant_mentions(
    answer: str,
    source_documents: List[Document]
) -> List[Dict[str, Any]]:
    """
    Extrai restaurantes mencionados na resposta com suporte a variaÃ§Ãµes de grafia.
    FASE 4: Melhoria para capturar variaÃ§Ãµes como "Papa John's" vs "Papa Johns".
    
    Returns:
        Lista de dicionÃ¡rios com 'name' e 'metadata'
    """
    mentions = []
    answer_lower = answer.lower()
    added_ids = set()  # Evitar duplicatas
    
    for doc in source_documents:
        metadata = doc.metadata if hasattr(doc, 'metadata') else {}
        if metadata.get('type') != 'restaurant':
            continue
        
        name = metadata.get('name', '').strip()
        if not name:
            continue
        
        # Criar variaÃ§Ãµes para busca (ex: com/sem apÃ³strofo, minÃºsculo, sem hÃ­fen)
        variations = [
            name.lower(),
            name.lower().replace("'", ""),
            name.lower().replace("'", ""),
            name.lower().replace("-", " "),
            name.lower().replace(".", ""),
            name.lower().replace("'", "").replace("-", " "),  # CombinaÃ§Ã£o
        ]
        
        # Verificar se alguma variaÃ§Ã£o estÃ¡ na resposta
        if any(v in answer_lower for v in variations):
            # Usar restaurant_id se disponÃ­vel, senÃ£o usar name como ID Ãºnico
            unique_id = metadata.get('restaurant_id') or metadata.get('id') or name
            
            if unique_id not in added_ids:
                mentions.append({
                    "name": name,
                    "metadata": metadata
                })
                added_ids.add(unique_id)
    
    return mentions


def extract_restaurant_description(answer: str, restaurant_name: str, max_len: int = 85) -> str:
    """
    Extrai descriÃ§Ã£o concisa, removendo fillers e truncando de forma inteligente.
    NÃ£o corta palavras ao meio.
    
    Args:
        answer: Resposta completa do LLM
        restaurant_name: Nome do restaurante
        max_len: Comprimento mÃ¡ximo da descriÃ§Ã£o (padrÃ£o: 85)
    
    Returns:
        DescriÃ§Ã£o limpa e concisa, ou string vazia se nÃ£o encontrada
    """
    # Blacklist de frases genÃ©ricas que nÃ£o agregam valor
    blacklist_phrases = [
        r'Ã© um restaurante que',
        r'oferece uma experiÃªncia de',
        r'famoso por ser',
        r'uma excelente opÃ§Ã£o para',
        r'experiÃªncia de churrasco',
        r'variedade de opÃ§Ãµes',
        r'ambiente acolhedor',
    ]
    
    # Procurar por padrÃµes como "X tem/Ã©/oferece..."
    patterns = [
        rf'\b{re.escape(restaurant_name)}\b[^.!?]*?([^.!?]+)',
        rf'\b{re.escape(restaurant_name)}\b.*?tem\s+([^.!?]+)',
        rf'\b{re.escape(restaurant_name)}\b.*?oferece\s+([^.!?]+)',
    ]
    
    desc = ""
    for pattern in patterns:
        match = re.search(pattern, answer, re.IGNORECASE)
        if match:
            desc = match.group(1).strip()
            break
    
    if not desc or len(desc) < 20:
        return ""
    
    # CORREÃ‡ÃƒO: Aplicar blacklist de forma conservadora
    # Apenas remover se a descriÃ§Ã£o for muito longa
    # E remover frases completas, nÃ£o partes
    if len(desc) > 100:
        # Remover apenas no inÃ­cio da frase (frases completas)
        blacklist_patterns = [
            r'^Ã‰ um restaurante que\s+',
            r'^Oferece uma experiÃªncia de\s+',
            r'^Famoso por ser\s+',
        ]
        for pattern in blacklist_patterns:
            desc = re.sub(pattern, '', desc, flags=re.IGNORECASE)
    
    desc = desc.strip()
    
    # Validar que a descriÃ§Ã£o faz sentido (nÃ£o tem palavras soltas)
    words = desc.split()
    if len(words) < 3:
        return ""  # Rejeitar se tiver menos de 3 palavras
    
    # Truncagem inteligente (nÃ£o corta palavras ao meio)
    if len(desc) <= max_len:
        return desc
    
    truncated = desc[:max_len]
    last_space = truncated.rfind(' ')
    if last_space != -1:
        truncated = truncated[:last_space]
    
    return truncated + "..."


def generate_comparison(restaurants: List[Dict[str, Any]]) -> str:
    """
    Gera comparaÃ§Ã£o rÃ¡pida entre restaurantes.
    """
    if len(restaurants) < 2:
        return ""
    
    names = [r['name'] for r in restaurants]
    if len(names) == 2:
        return f"{names[0]} Ã© mais premium, enquanto {names[1]} Ã© mais acessÃ­vel."
    else:
        return f"{names[0]} Ã© premium, {names[1]} Ã© intermediÃ¡rio, e {names[2]} Ã© mais acessÃ­vel."

