#!/usr/bin/env python3
"""
Teste unit√°rio da l√≥gica do Chef Recomenda.
Testa as fun√ß√µes diretamente sem precisar do servidor rodando.
"""

import sys
import os

# Adicionar o backend ao path
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'tastematch', 'backend'))

def test_imports():
    """Testa se todos os imports est√£o corretos."""
    print("üß™ Testando imports...")
    
    try:
        from app.core.recommender import select_chef_recommendation
        print("‚úÖ select_chef_recommendation importado com sucesso")
    except Exception as e:
        print(f"‚ùå Erro ao importar select_chef_recommendation: {e}")
        return False
    
    try:
        from app.core.llm_service import generate_chef_explanation, build_chef_explanation_prompt
        print("‚úÖ generate_chef_explanation e build_chef_explanation_prompt importados com sucesso")
    except Exception as e:
        print(f"‚ùå Erro ao importar fun√ß√µes do llm_service: {e}")
        return False
    
    try:
        from app.api.routes.recommendations import ChefRecommendationResponse
        print("‚úÖ ChefRecommendationResponse importado com sucesso")
    except Exception as e:
        print(f"‚ùå Erro ao importar ChefRecommendationResponse: {e}")
        return False
    
    return True

def test_chef_selection_logic():
    """Testa a l√≥gica de sele√ß√£o do Chef."""
    print("\nüß™ Testando l√≥gica de sele√ß√£o do Chef...")
    
    try:
        from app.core.recommender import select_chef_recommendation
        from unittest.mock import MagicMock
        
        # Criar mock de recomenda√ß√µes
        mock_recommendations = [
            {
                "restaurant": MagicMock(
                    id=1,
                    name="Restaurante A",
                    cuisine_type="japonesa",
                    rating=4.5
                ),
                "similarity_score": 0.85
            },
            {
                "restaurant": MagicMock(
                    id=2,
                    name="Restaurante B",
                    cuisine_type="brasileira",
                    rating=4.8
                ),
                "similarity_score": 0.75
            },
            {
                "restaurant": MagicMock(
                    id=3,
                    name="Restaurante C",
                    cuisine_type="italiana",
                    rating=4.2
                ),
                "similarity_score": 0.90
            }
        ]
        
        # Criar mock de dados
        mock_orders = []
        mock_db = MagicMock()
        
        # Testar a fun√ß√£o
        result = select_chef_recommendation(
            recommendations=mock_recommendations,
            user_id=1,
            orders=mock_orders,
            db=mock_db
        )
        
        if result:
            print("‚úÖ Fun√ß√£o select_chef_recommendation executada com sucesso")
            print(f"   Restaurante selecionado: {result['restaurant'].name}")
            print(f"   Score final: {result.get('final_score', 0):.2f}")
            print(f"   Confian√ßa: {result.get('confidence', 0):.2%}")
            print(f"   Raz√µes: {len(result.get('reasoning', []))}")
            return True
        else:
            print("‚ùå Fun√ß√£o retornou None")
            return False
            
    except Exception as e:
        print(f"‚ùå Erro ao testar l√≥gica de sele√ß√£o: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_chef_explanation_prompt():
    """Testa a constru√ß√£o do prompt de explica√ß√£o."""
    print("\nüß™ Testando constru√ß√£o do prompt de explica√ß√£o...")
    
    try:
        from app.core.llm_service import build_chef_explanation_prompt
        from unittest.mock import MagicMock
        
        mock_restaurant = MagicMock(
            name="Sushi House",
            cuisine_type="japonesa",
            rating=4.7,
            description="Restaurante de sushi tradicional",
            price_range="medium"
        )
        
        user_context = {
            "name": "Jo√£o",
            "total_orders": 10,
            "favorite_cuisines": ["japonesa", "brasileira"]
        }
        
        reasoning = [
            "Alta similaridade com suas prefer√™ncias",
            "Excelente avalia√ß√£o (4.7/5.0)",
            "Restaurante novo para voc√™"
        ]
        
        prompt = build_chef_explanation_prompt(
            user_context=user_context,
            restaurant=mock_restaurant,
            reasoning=reasoning,
            similarity_score=0.85,
            confidence=0.90
        )
        
        if prompt and len(prompt) > 100:
            print("‚úÖ Prompt constru√≠do com sucesso")
            print(f"   Tamanho do prompt: {len(prompt)} caracteres")
            print(f"   Cont√©m 'Sushi House': {'Sushi House' in prompt}")
            print(f"   Cont√©m 'japonesa': {'japonesa' in prompt}")
            print(f"   Cont√©m raz√µes: {all(r in prompt for r in reasoning)}")
            return True
        else:
            print("‚ùå Prompt inv√°lido ou muito curto")
            return False
            
    except Exception as e:
        print(f"‚ùå Erro ao testar prompt: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_model_response():
    """Testa se o modelo de resposta pode ser criado."""
    print("\nüß™ Testando modelo de resposta...")
    
    try:
        from app.api.routes.recommendations import ChefRecommendationResponse
        from app.models.restaurant import RestaurantResponse
        from datetime import datetime
        from unittest.mock import MagicMock
        
        mock_restaurant_response = RestaurantResponse(
            id=1,
            name="Test Restaurant",
            cuisine_type="japonesa",
            rating=4.5,
            created_at=datetime.now()
        )
        
        response = ChefRecommendationResponse(
            restaurant=mock_restaurant_response,
            similarity_score=0.85,
            explanation="Esta √© uma explica√ß√£o de teste",
            reasoning=["Raz√£o 1", "Raz√£o 2"],
            confidence=0.90,
            generated_at=datetime.now()
        )
        
        print("‚úÖ ChefRecommendationResponse criado com sucesso")
        print(f"   Restaurante: {response.restaurant.name}")
        print(f"   Similaridade: {response.similarity_score:.2%}")
        print(f"   Confian√ßa: {response.confidence:.2%}")
        print(f"   Raz√µes: {len(response.reasoning)}")
        return True
        
    except Exception as e:
        print(f"‚ùå Erro ao criar modelo: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """Fun√ß√£o principal de teste."""
    print("\n" + "=" * 60)
    print("  TESTE UNIT√ÅRIO DA L√ìGICA DO CHEF RECOMENDA")
    print("=" * 60)
    
    results = []
    
    # Testar imports
    results.append(("Imports", test_imports()))
    
    # Testar l√≥gica de sele√ß√£o
    results.append(("L√≥gica de Sele√ß√£o", test_chef_selection_logic()))
    
    # Testar prompt
    results.append(("Constru√ß√£o do Prompt", test_chef_explanation_prompt()))
    
    # Testar modelo
    results.append(("Modelo de Resposta", test_model_response()))
    
    # Resumo
    print("\n" + "=" * 60)
    print("  RESUMO DOS TESTES")
    print("=" * 60)
    
    for name, result in results:
        status = "‚úÖ PASSOU" if result else "‚ùå FALHOU"
        print(f"{status}: {name}")
    
    passed = sum(1 for _, result in results if result)
    total = len(results)
    
    print(f"\nTotal: {passed}/{total} testes passaram")
    
    if passed == total:
        print("\n‚úÖ Todos os testes passaram! A implementa√ß√£o est√° correta.")
        return 0
    else:
        print(f"\n‚ùå {total - passed} teste(s) falharam.")
        return 1

if __name__ == "__main__":
    sys.exit(main())

